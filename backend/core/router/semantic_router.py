# core/router/semantic_router.py
from __future__ import annotations

import json
import re

from typing import List, cast
from langchain_core.prompts import ChatPromptTemplate

from config.dicionarios import TEMPLATE_TEMA, llm, TEMAS_VALIDOS, THEME_KEYWORDS
from utils.logger import get_logger

logger = get_logger(__name__)

# üöÄ Palavras que devem for√ßar o tema 'institucional'
PALAVRAS_INSTITUCIONAL = [
    "grupo houer",
    "houer",
    "empresa",
    "qualidade",
    "certifica√ß√£o",
    "infraestrutura",
    "sustentabilidade",
    "projetos de engenharia",
    "ppp",
    "concess√£o",
]


def classificar_tema(pergunta: str) -> str:
    """
    Classifica a pergunta em um dos temas definidos em TEMAS_VALIDOS ou retorna 'llm' como fallback.
    Usa primeiro regras baseadas em keywords, e finalmente o LLM com TEMPLATE_TEMA se nada corresponder.
    """
    texto = pergunta or ""
    lower = texto.lower()

    # 0Ô∏è‚É£ Regras espec√≠ficas para institucional
    if any(palavra in lower for palavra in PALAVRAS_INSTITUCIONAL):
        logger.info("üîµ Tema classificado manualmente como 'institucional'")
        return "institucional"

    # 1Ô∏è‚É£ Regras baseadas em keywords (populacao, economia, educacao, tecnica)
    for tema, patterns in THEME_KEYWORDS.items():
        if tema == "comparative":
            continue
        for pat in patterns:
            if re.search(pat, lower):
                logger.info(f"‚öôÔ∏è Tema classificado via regra: {tema}")
                # deixa expl√≠cito pro MyPy que √© str
                return cast(str, tema)

    # 2Ô∏è‚É£ Fallback via LLM usando TEMPLATE_TEMA
    logger.info("üîÑ Nenhuma regra bateu. Classificando com LLM via TEMPLATE_TEMA")
    try:
        prompt_msgs = ChatPromptTemplate.from_template(TEMPLATE_TEMA).format_messages(
            pergunta=pergunta
        )
        resposta = llm.invoke(prompt_msgs)
        content = (resposta.content or "").strip()
        content = content.replace("```json", "").replace("```", "").strip()
        logger.debug(f"üß† Sa√≠da bruta da LLM:\n{content}")

        # tenta interpretar como JSON garantindo str
        tema_llm: str = ""
        try:
            parsed = json.loads(content)
            if isinstance(parsed, dict):
                raw = parsed.get("tema", "")
                tema_llm = raw if isinstance(raw, str) else ""
            elif isinstance(parsed, str):
                tema_llm = parsed
        except json.JSONDecodeError:
            m = re.search(r'"?tema"?\s*:\s*"?(?P<t>\w+)"?', content)
            if m and isinstance(m.group("t"), str):
                tema_llm = m.group("t")

        tema_llm = tema_llm.lower().strip()
        if tema_llm in TEMAS_VALIDOS:
            logger.info(f"‚úÖ Tema classificado via LLM: {tema_llm}")
            return tema_llm
        logger.warning(f"‚ö†Ô∏è LLM retornou tema inv√°lido: '{tema_llm}'")
    except Exception as e:
        logger.error(f"‚ùå Erro no fallback LLM: {e}")

    # 3Ô∏è‚É£ Fallback final
    logger.info("‚ö†Ô∏è Fallback final, atribuindo tema 'llm'")
    return "llm"
