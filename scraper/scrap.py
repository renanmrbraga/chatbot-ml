# backend/scraping/scrap.py
from typing import Callable, List, Tuple
from utils.logger import get_logger
from .scraper_sidra_ibge import run as run_sidra
from .city_data_sidra_to_csv import run as run_to_csv
from .insert_database import run as run_insert

logger = get_logger(__name__)


def main() -> None:
    logger.info("ğŸš€ Iniciando pipeline de scraping completo...")

    etapas: List[Tuple[str, Callable[[], None]]] = [
        ("ğŸ” Etapa 1â€¯â€“ Coleta do SIDRA (IBGE)", run_sidra),
        ("ğŸ“„ Etapa 2â€¯â€“ GeraÃ§Ã£o do CSV final", run_to_csv),
        ("ğŸ“¥ Etapa 3â€¯â€“ InserÃ§Ã£o no banco (educaÃ§Ã£o + tÃ©cnica)", run_insert),
    ]

    for titulo, func in etapas:
        logger.info(titulo)
        try:
            func()
        except Exception as e:
            logger.critical(f"âŒ Falha na etapa: {titulo} â†’ {e}")
            logger.critical("ğŸ›‘ Pipeline encerrado devido a erro crÃ­tico.")
            break
    else:
        logger.success("âœ… Pipeline executado com sucesso! Dados atualizados.")


if __name__ == "__main__":
    main()
